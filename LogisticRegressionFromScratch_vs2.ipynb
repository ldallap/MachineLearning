{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f67bc72",
   "metadata": {},
   "source": [
    "##### RESOURCES:\n",
    "\n",
    "1) Coursera: Neural Networks and Deep Learning\\\n",
    "2) https://www.youtube.com/watch?v=w8yWXqWQYmU&t=664s&ab_channel=SamsonZhang \\\n",
    "3) https://medium.com/@jacobbumgarner/breaking-it-down-logistic-regression-e5c3f1450bd#cee3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98ed267b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# For animation\n",
    "from celluloid import Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80f1ec40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Logistic Regression\n",
    "    Args:\n",
    "        n_input_features (int): # of features in the dataset\n",
    "    Attirbutes:\n",
    "        weights (np.ndarray)\n",
    "        bias (float)\n",
    "        fit (bool): Whether the model has been fit or not to training data. Default: False\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_input_features: int):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "            Initialize weights (W) and bias (b)    \n",
    "        \"\"\"\n",
    "        self.weights = np.random.randn(n_input_features,1)*0.01 # Do not start with zeros. Font: Andrew NG course\n",
    "        self.bias = np.zeros((1,1))\n",
    "        \n",
    "        self.fit = False # indicates the training state of the classifier\n",
    "        \n",
    "    \n",
    "    def linear_transform(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Description:\n",
    "            Linear component\n",
    "            Z = W X + b\n",
    "        \n",
    "        Args:\n",
    "            X (np.ndarray): Input data\n",
    "        \n",
    "        Returns:\n",
    "            np.ndarray: transformed data Z\n",
    "        \n",
    "        W -> weights\n",
    "        b -> bias\n",
    "        X -> Input data\n",
    "        \"\"\"\n",
    "        return np.matmul(X, self.weights) + self.bias # np.matmul = matrix multiplication line vs colunm\n",
    "    \n",
    "    def sigmoid(self, Z: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Description:\n",
    "            Sigmoid function\n",
    "            sigma(z) = 1 / (1 + exp(-z))\n",
    "        \n",
    "        Args:\n",
    "            Z (np.ndarray): Linear transformed data\n",
    "        \n",
    "        Returns:\n",
    "            np.ndarray: Data evaluated in a sigmoid function\n",
    "        \"\"\"\n",
    "        return 1. / (1. + np.exp(-Z))\n",
    "        \n",
    "    \n",
    "    def cost_cross_entropy(self, A: np.ndarray, Y: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Description:\n",
    "            Cross-Entropy Cost Function\n",
    "            L(Y,A) = (1/m) \\sum_n [(-Y log(A)) - (1-Y)(log(1-A))]\n",
    "            \n",
    "        Args:\n",
    "            Y (np.ndarray): true label of the data\n",
    "            A (np.ndarray): label \"probability\" \n",
    "        \"\"\"\n",
    "        m = Y.shape[0]\n",
    "        epsilon = 1e-6\n",
    "        \n",
    "        cost = (-1/m) * np.sum( Y*np.log(A)  + \\\n",
    "                (1 - Y) * np.log(1-A+epsilon))\n",
    "        \n",
    "        # cost = np.squeeze(cost) make sure cost is in the correct shape (turn [[1]] into 1)\n",
    "        return np.squeeze(cost)\n",
    "    \n",
    "    def gradient_descent(self, X: np.ndarray, A: np.ndarray, Y: np.ndarray,\n",
    "                        learning_rate = 0.01) -> None:\n",
    "        \"\"\"\n",
    "        Description:\n",
    "            Compute the Gradient Descent\n",
    "            dZ = (A - Y)\n",
    "            dW = dZ . X \n",
    "            dB = dZ\n",
    "                and update\n",
    "            W = W - dW * learning_rate\n",
    "            b = b - dB * learning_rate\n",
    "        \"\"\"\n",
    "        m = A.shape[0]\n",
    "        oneover_m = 1./m\n",
    "        \n",
    "        dZ = (A - Y)\n",
    "        dW = oneover_m * np.sum(dZ * X, axis=0, keepdims=True).T\n",
    "        dB = oneover_m * np.sum(dZ, axis=0, keepdims=True).T\n",
    "        \n",
    "        # Update\n",
    "        self.weights -= dW * learning_rate\n",
    "        self.bias -= dB * learning_rate\n",
    "        \n",
    "        return\n",
    "        \n",
    "        \n",
    "    def train(self, X: np.ndarray, Y: np.ndarray,\n",
    "             epochs: int = 100, learning_rate: float = 0.01, batch_size: int = 10,\n",
    "             verbose: bool = False) -> np.ndarray:\n",
    "        \n",
    "        \"\"\"\n",
    "        Description:\n",
    "            Fit the logistic regression model to training data\n",
    "            Use minibatch GD.\n",
    "            \n",
    "        Args:\n",
    "            X (np.ndarray): Training dataset\n",
    "            Y (np.ndarray): Training targets\n",
    "            epochs (int, optional; default = 100): Number of iterations\n",
    "            learning_rate (float, optional; default = 0.01): Learning rate step size\n",
    "            batch_size (int, optional; default = 10): Size of batch for GD\n",
    "            verbose (bool, optional; default = False): __description__\n",
    "        \n",
    "        Raises:\n",
    "            Attribute: Raises error if the model is already fitted\n",
    "            ValueError: Raises error if the number of features dosen't match the instantiated feature count.\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: The cost history\n",
    "        \n",
    "        \"\"\"\n",
    "        # Raise flags\n",
    "        if self.fit:\n",
    "            raise AttributeError(\"Error: Model already fitted\")\n",
    "        self.fit = True\n",
    "        \n",
    "        if not X.shape[-1] == self.weights.shape[0]:\n",
    "            raise ValueError(\"Shape of X is different from Weights\")\n",
    "        \n",
    "        if Y.ndim == 1:\n",
    "            Y = np.expand_dims(Y, axis=1)\n",
    "        \n",
    "        # Fit the model\n",
    "        cost_hist = []\n",
    "        accuracies = []\n",
    "        weight_hist = []\n",
    "        bias_hist = []\n",
    "        \n",
    "        for _ in range(epochs):\n",
    "            weight_hist.append(self.weights[:,0].copy())\n",
    "            bias_hist.append(self.bias.copy())\n",
    "            \n",
    "            \n",
    "            if batch_size:\n",
    "                batch_indices = np.random.choice(\n",
    "                    X.shape[0], size = batch_size, replace = False\n",
    "                )\n",
    "                X_batch, Y_batch = X[batch_indices], Y[batch_indices]\n",
    "            else:\n",
    "                X_batch, Y_batch = X, Y\n",
    "                \n",
    "            \n",
    "            # Linear Transformation\n",
    "            Z = self.linear_transform(X_batch)\n",
    "            \n",
    "            # Sigmoid activation\n",
    "            A = self.sigmoid(Z)\n",
    "            \n",
    "            # Cost function (Cross- Entropy)\n",
    "            cost = self.cost_cross_entropy(A, Y_batch)\n",
    "            \n",
    "            # Perform GD\n",
    "            self.gradient_descent(X_batch, A, Y_batch, learning_rate = learning_rate)\n",
    "            \n",
    "            if verbose:\n",
    "                print(f'Epoch: {_}, Cost: {cost: 0.3f}                  ', end='\\r')\n",
    "                \n",
    "            cost_hist.append(cost)\n",
    "            accuracies.append(self.accuracy(self.predict(X), Y[:,0]))\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'Final cost: {cost:0.2f}                  ')\n",
    "            \n",
    "        self.fit = True\n",
    "        \n",
    "        return np.array(cost_hist), np.array(accuracies), np.array(weight_hist).T, np.array(bias_hist).T[0,0]\n",
    "    \n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Description:\n",
    "            Predict the labels\n",
    "            \n",
    "        Args:\n",
    "            X (np.ndarray): Data for predictions\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: Prediction for each sample\n",
    "        \"\"\"\n",
    "        if not self.fit:\n",
    "            raise AttributeError(\"Error: This classifier is not trained\")\n",
    "        \n",
    "        Z = self.linear_transform(X)\n",
    "        A = self.sigmoid(Z)\n",
    "        \n",
    "        return A.T[0]\n",
    "    \n",
    "    def accuracy(self, predictions: np.ndarray, labels: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Description:\n",
    "            Accuracy of prediction\n",
    "            \n",
    "        Args:\n",
    "            predictions (np.ndarray): predict (function) output\n",
    "            labels (np.ndarray): True labels\n",
    "            \n",
    "        Returns:\n",
    "            float: prediction accuracy\n",
    "        \"\"\"\n",
    "        \n",
    "        overlap = (predictions >= 0.5) == labels\n",
    "        accuracy = (overlap.sum() / predictions.shape[0]) * 100 # convert to probability\n",
    "        \n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac60cbf5",
   "metadata": {},
   "source": [
    "Load DataSet = UCI Heart Disease Dataset\n",
    "\n",
    "Transform the data to feed the model\n",
    "\n",
    "i) Split dataset by hand\n",
    "\n",
    "or\n",
    "\n",
    "ii) using sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58e4d8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"Dataset/heart.csv\")\n",
    "\n",
    "# # Target are 0=yes and 1=no, let's change\n",
    "# df.target = df.target.replace({0: 1, 1: 0})\n",
    "# # print(df.head())\n",
    "# # print(df.tail())\n",
    "\n",
    "\n",
    "# df = df[['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'target']]\n",
    "\n",
    "# # Method (i)\n",
    "\n",
    "# # # Normalize the data\n",
    "# FeaturesToNormalize = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "    \n",
    "# for _ in FeaturesToNormalize:\n",
    "#     df[_] = ( df[_] - df[_].mean() ) / df[_].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ea02acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Method (i)\n",
    "# # Be careful with data leakage\n",
    "\n",
    "# x_train = df.sample(frac=0.75,random_state=42)\n",
    "# x_test = df.drop(x_train.index)\n",
    "\n",
    "# y_train = x_train['target']\n",
    "# y_test = x_test['target']\n",
    "\n",
    "# x_train = x_train.drop(['target'], axis=1)\n",
    "# x_test = x_test.drop(['target'], axis=1)\n",
    "    \n",
    "# x_train = x_train.to_numpy()\n",
    "# x_test = x_test.to_numpy()\n",
    "\n",
    "# y_train = y_train.to_numpy()\n",
    "# y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d31c985d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method (ii)\n",
    "\n",
    "df = pd.read_csv(\"Dataset/heart.csv\")\n",
    "\n",
    "# Target are 0=yes and 1=no, let's change\n",
    "df.target = df.target.replace({0: 1, 1: 0})\n",
    "\n",
    "targets = df.pop(\"target\")\n",
    "# print(df.head())\n",
    "# print(df.tail())\n",
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    df, targets, test_size = 0.25, random_state = 42\n",
    ")\n",
    "\n",
    "features_to_standardize = [\"age\", \"trestbps\", \"chol\", \"thalach\", \"oldpeak\"]\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "    [(\"scaler\", StandardScaler(), features_to_standardize)], remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "x_train = column_transformer.fit_transform(x_train)\n",
    "x_test = column_transformer.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1421dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf99000",
   "metadata": {},
   "source": [
    "Training and testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27fdb773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test accuracy: 85.53%\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(n_input_features=x_train.shape[-1])\n",
    "\n",
    "costs, accuracies, weights, bias = model.train(x_train, y_train,\n",
    "                                              epochs = 5000,\n",
    "                                              learning_rate=0.01,\n",
    "                                              batch_size=None,\n",
    "                                              verbose=False)\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "accuracy = model.accuracy(predictions, y_test)\n",
    "\n",
    "print(f\"Model test accuracy: {accuracy:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df2be89",
   "metadata": {},
   "source": [
    "Make a video animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bd0ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = \"/Users/ldallap/Desktop/Github/MachineLearning/example.mp4\"\n",
    "\n",
    "# movie_duration = 5\n",
    "# fps = 30\n",
    "\n",
    "\n",
    "# plt.style.use(\"dark_background\")\n",
    "\n",
    "\n",
    "# fig = plt.figure(figsize=(10, 8))\n",
    "\n",
    "# gs = fig.add_gridspec(2, 6, hspace=0.25, wspace=1)\n",
    "\n",
    "# ax1 = fig.add_subplot(gs[0,:3])\n",
    "\n",
    "# ax2 = fig.add_subplot(gs[0, 3:], sharex = ax1)\n",
    "\n",
    "# ax3 = fig.add_subplot(gs[1, :4], sharex = ax1)\n",
    "\n",
    "# ax4 = fig.add_subplot(gs[1, 4:], sharex = ax1)\n",
    "\n",
    "# cost_color = \"#78cdbf\"\n",
    "# accuracy_color = \"#d63a64\"\n",
    "# weights_colormap = plt.get_cmap(\"inferno\")\n",
    "# bias_color = \"#f59c53\"\n",
    "\n",
    "\n",
    "# camera = Camera(fig)\n",
    "# frame_density = int(costs.shape[0] / (movie_duration * fps))\n",
    "\n",
    "# for i in range(0, costs.shape[0], frame_density):\n",
    "\n",
    "#     ax1.plot(np.arange(0,i), costs[:i], c=cost_color)\n",
    "#     ax2.plot(np.arange(0,i), accuracies[:i], c=accuracy_color)\n",
    "\n",
    "#     for _ in range(model.weights.shape[0]):\n",
    "#         ax3.plot(np.arange(0,i), weights[_,:i], c=weights_colormap(_/model.weights.shape[0]))\n",
    "\n",
    "#     ax4.plot(np.arange(0,i), bias[:i], c=bias_color)\n",
    "    \n",
    "#     camera.snap()\n",
    "    \n",
    "# animation = camera.animate()\n",
    "# animation.save(save_path, dpi=300, fps=fps,\n",
    "#                progress_callback = lambda i, n:\n",
    "#                print(f'Saving frame {i} of {int(costs.shape[0]/frame_density)}', end=\"\\r\"))\n",
    "\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f9fccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import HTML\n",
    "# HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d99553",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
